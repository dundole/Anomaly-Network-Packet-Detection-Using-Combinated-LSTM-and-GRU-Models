{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# keras\n",
    "import keras\n",
    "from keras import models, optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
    "from keras import Model ,models, layers, optimizers, regularizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend.tensorflow_backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-merchandise",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 셋 load\n",
    "valid_label = np.load('dataset/valid_label_AE.npy')\n",
    "test_label = np.load('dataset/test_label_AE.npy')\n",
    "\n",
    "train_normal_scaled = np.load('dataset/train_normal_scaled_AE.npy')\n",
    "valid_normal_scaled = np.load('dataset/valid_normal_scaled_AE.npy')\n",
    "valid_scaled = np.load('dataset/valid_scaled_AE.npy')\n",
    "test_scaled = np.load('dataset/test_scaled_AE.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# timesteps 설정\n",
    "# ************************** #\n",
    "timesteps = 10\n",
    "# ************************** #\n",
    "\n",
    "# timesteps로 나눈 나머지 산출\n",
    "train_normal_rest = -(train_normal_scaled.shape[0] % timesteps)\n",
    "valid_normal_rest = -(valid_normal_scaled.shape[0] % timesteps)\n",
    "valid_rest = -(valid_scaled.shape[0] % timesteps)\n",
    "test_rest = -(test_scaled.shape[0] % timesteps)\n",
    "\n",
    "# 나머지만큼 데이터셋 절삭\n",
    "train_normal_scaled = train_normal_scaled[:train_normal_rest]\n",
    "valid_normal_scaled = valid_normal_scaled[:valid_normal_rest]\n",
    "valid_scaled = valid_scaled[:valid_rest]\n",
    "test_scaled = test_scaled[:test_rest]\n",
    "\n",
    "valid_label = valid_label[:valid_rest]\n",
    "test_label = test_label[:test_rest]\n",
    "\n",
    "# 3차원으로 데이터 변환\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_normal_scaled_reshape = train_normal_scaled.reshape((int(train_normal_scaled.shape[0]/timesteps), timesteps, train_normal_scaled.shape[1]))\n",
    "valid_normal_scaled_reshape = valid_normal_scaled.reshape((int(valid_normal_scaled.shape[0]/timesteps), timesteps, valid_normal_scaled.shape[1])) \n",
    "valid_scaled_reshape = valid_scaled.reshape((int(valid_scaled.shape[0]/timesteps), timesteps, valid_scaled.shape[1])) \n",
    "test_scaled_reshape = test_scaled.reshape((int(test_scaled.shape[0]/timesteps), timesteps, test_scaled.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001 # 학습률(learning rate)\n",
    "batch = 100 # batch size\n",
    "epochs = 10\n",
    "\n",
    "# 모델생성\n",
    "with K.tf.device('/gpu:0'):\n",
    "    lstm_ae = models.Sequential()\n",
    "    # Encoder\n",
    "    lstm_ae.add(layers.LSTM(64, activation='relu', input_shape=(timesteps, 78), return_sequences=True))\n",
    "    lstm_ae.add(layers.LSTM(32, activation='relu', return_sequences=True))\n",
    "    lstm_ae.add(layers.LSTM(16, activation='relu', return_sequences=False))\n",
    "    lstm_ae.add(layers.RepeatVector(timesteps))\n",
    "    # Decoder\n",
    "    lstm_ae.add(layers.LSTM(16, activation='relu', return_sequences=True))\n",
    "    lstm_ae.add(layers.LSTM(32, activation='relu', return_sequences=True))\n",
    "    lstm_ae.add(layers.LSTM(64, activation='relu', return_sequences=True))\n",
    "    lstm_ae.add(layers.TimeDistributed(layers.Dense(78)))\n",
    "          \n",
    "   # compile\n",
    "    lstm_ae.compile(loss='mse', optimizer=optimizers.Adam(lr=lr), metrics=['accuracy'],)\n",
    "          \n",
    "    # fit\n",
    "    history = lstm_ae.fit(train_normal_scaled_reshape, train_normal_scaled_reshape,\n",
    "                              epochs=epochs, batch_size=batch,\n",
    "                              validation_data=(valid_normal_scaled_reshape, valid_normal_scaled_reshape))\n",
    "    # 모델 저장\n",
    "    lstm_ae.save('./model/lstm_ae.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-occasions",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_ae = models.load_model('./model/lstm_ae.h5')\n",
    "\n",
    "# valid 데이터셋으로 예측 수행\n",
    "valid_predictions = lstm_ae.predict(valid_scaled_reshape)\n",
    "\n",
    "# 복원 오차 산출\n",
    "mse = np.mean(np.power(valid_scaled - valid_predictions.reshape(valid_predictions.shape[0]*timesteps, 78), 2), axis=1)\n",
    "\n",
    "\n",
    "best_f1 = 0\n",
    "best_th = 0.9\n",
    "i = best_th\n",
    "\n",
    "# 최적의 threshold 산출\n",
    "while True:\n",
    "    if i == 0.1:\n",
    "        break\n",
    "        \n",
    "    mse_th = mse.copy()\n",
    "    mse_th[mse_th < i] = 0\n",
    "    mse_th[mse_th >= i] = 1\n",
    "    \n",
    "    f1 = f1_score(valid_label_rest, mse_th)*100\n",
    "    if f1 > best_f1:\n",
    "        pr = precision_score(label, result_cp)*100\n",
    "        if pr > best_pr:\n",
    "            best_th = i\n",
    "            best_f1 = f1\n",
    "            best_pr = pr\n",
    "    i -= 0.0002\n",
    "    del [[mse_th]]\n",
    "\n",
    "print('\\n\\n')        \n",
    "print('best f1 : ', best_f1)\n",
    "print('best th : ', best_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터 셋으로 예측 수행\n",
    "test_predictions = lstm_ae.predict(test_scaled_reshape)\n",
    "\n",
    "# 복원 오차 산출\n",
    "mse = np.mean(np.power(test_scaled - test_predictions.reshape(test_predictions.shape[0]*timesteps, 78), 2), axis=1)\n",
    "\n",
    "# threshold 기준으로 분류\n",
    "mse[mse < best_th] = 0\n",
    "mse[mse >= best_th] = 1\n",
    "\n",
    "# 결과 가시화\n",
    "print(\"accuracy_score :\",accuracy_score(test_label_rest, mse)*100)\n",
    "print(\"recall_score :\",recall_score(test_label_rest, mse)*100)\n",
    "print(\"precision_score :\",precision_score(test_label_rest, mse)*100)\n",
    "print(\"f1_score :\",f1_score(test_label_rest, mse)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
