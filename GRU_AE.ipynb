{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# keras\n",
    "import keras\n",
    "from keras import models, optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, GRU, LeakyReLU\n",
    "from keras import Model ,models, layers, optimizers, regularizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend.tensorflow_backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"dataset/total2.csv\", index_col=2)\n",
    "\n",
    "\n",
    "# 라벨 처리\n",
    "train_df.loc[train_df['Label'] != 'Benign', \"Label\"] = 1\n",
    "train_df.loc[train_df['Label'] == 'Benign', \"Label\"] = 0\n",
    "\n",
    "train_df = train_df.apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "#결측치 제거\n",
    "train_df = train_df.replace([np.inf, -np.inf], np.nan)\n",
    "train_df.fillna(0.0,inplace=True)\n",
    "\n",
    "# 정상만 학습 (학습_정상 70%, 탐지_정상+악성 30%)\n",
    "x_train, x_test = train_test_split(train_df, test_size=0.3)\n",
    "x_train, x_val = train_test_split(x_train, test_size=0.3)\n",
    "\n",
    "# 학습용 라벨 분리\n",
    "train_label = x_train['Label']\n",
    "valid_label = x_val['Label'].astype('float64').values\n",
    "test_label = x_test['Label'].astype('float64').values\n",
    "\n",
    "x_valid = x_val.drop('Label',axis=1).values\n",
    "x_test = x_test.drop('Label', axis=1).values\n",
    "\n",
    "# 정상만 분리\n",
    "x_train_y0 = x_train[train_label == 0].drop('Label',axis=1).values\n",
    "x_train_y1 = x_train[train_label == 1].drop('Label',axis=1).values\n",
    "\n",
    "x_valid_y0 = x_val[valid_label == 0].drop('Label',axis=1).values\n",
    "x_valid_y1 = x_val[valid_label == 1].drop('Label',axis=1).values\n",
    "\n",
    "# 라벨 데이터 저장\n",
    "np.save('dataset/valid_label.npy', valid_label)\n",
    "np.save('dataset/test_label.npy', test_label)\n",
    "\n",
    "\n",
    "# min max 정규화\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "x_train_y0_scaled = scaler.fit_transform(x_train_y0)\n",
    "x_valid_y0_scaled = scaler.fit_transform(x_valid_y0)\n",
    "x_valid_scaled = scaler.fit_transform(x_valid)\n",
    "x_test_scaled = scaler.fit_transform(x_test)\n",
    "\n",
    "# train, valid, test 데이터 저장\n",
    "np.save('dataset/x_train_y0_scaled.npy', x_train_y0_scaled)\n",
    "np.save('dataset/x_valid_y0_scaled.npy', x_valid_y0_scaled)\n",
    "np.save('dataset/x_valid_scaled.npy', x_valid_scaled)\n",
    "np.save('dataset/x_test_scaled.npy', x_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 load\n",
    "valid_label = np.load('dataset/valid_label.npy')\n",
    "test_label = np.load('dataset/test_label.npy')\n",
    "\n",
    "x_train_y0_scaled = np.load('dataset/x_train_y0_scaled.npy')\n",
    "x_valid_y0_scaled = np.load('dataset/x_valid_y0_scaled.npy')\n",
    "x_valid_scaled = np.load('dataset/x_valid_scaled.npy')\n",
    "x_test_scaled = np.load('dataset/x_test_scaled.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# timesteps 설정\n",
    "# ************************** #\n",
    "timesteps = 10\n",
    "# ************************** #\n",
    "\n",
    "# timesteps로 나눈 나머지 산출\n",
    "x_train_y0_rest = -(x_train_y0_scaled.shape[0] % timesteps)\n",
    "x_valid_y0_rest = -(x_valid_y0_scaled.shape[0] % timesteps)\n",
    "x_valid_rest = -(x_valid_scaled.shape[0] % timesteps)\n",
    "x_test_rest = -(x_test_scaled.shape[0] % timesteps)\n",
    "\n",
    "# 나머지만큼 데이터셋 절삭\n",
    "x_train_y0_scaled = x_train_y0_scaled[:x_train_y0_rest]\n",
    "x_valid_y0_scaled = x_valid_y0_scaled[:x_valid_y0_rest]\n",
    "x_valid_scaled = x_valid_scaled[:x_valid_rest]\n",
    "x_test_scaled = x_test_scaled[:x_test_rest]\n",
    "\n",
    "valid_label_rest = valid_label[:x_valid_rest]\n",
    "test_label_rest = test_label[:x_test_rest]\n",
    "\n",
    "# 3차원으로 데이터 변환\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "x_train_y0_scaled_reshape = x_train_y0_scaled.reshape((int(x_train_y0_scaled.shape[0]/timesteps), timesteps, x_train_y0_scaled.shape[1])) # 정상 데이터 셋\n",
    "x_valid_y0_scaled_reshape = x_valid_y0_scaled.reshape((int(x_valid_y0_scaled.shape[0]/timesteps), timesteps, x_valid_y0_scaled.shape[1])) # 테스트 데이터 셋\n",
    "x_valid_scaled_reshape = x_valid_scaled.reshape((int(x_valid_scaled.shape[0]/timesteps), timesteps, x_valid_scaled.shape[1])) # 테스트 데이터 셋\n",
    "x_test_scaled_reshape = x_test_scaled.reshape((int(x_test_scaled.shape[0]/timesteps), timesteps, x_test_scaled.shape[1])) # 테스트 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = 0.001 # 학습률(learning rate)\n",
    "batch = 100 # batch size\n",
    "epochs = 10\n",
    "\n",
    "# # 모델생성\n",
    "with K.tf.device('/gpu:0'):\n",
    "    print(\"GPU load 완료\",end=' / ')\n",
    "    lstm_ae = models.Sequential()\n",
    "    # Encoder\n",
    "    lstm_ae.add(layers.GRU(64, activation='relu', input_shape=(timesteps, 78), return_sequences=True))\n",
    "    lstm_ae.add(layers.GRU(32, activation='relu', return_sequences=True))\n",
    "    lstm_ae.add(layers.GRU(16, activation='relu', return_sequences=False))\n",
    "    lstm_ae.add(layers.RepeatVector(timesteps))\n",
    "    \n",
    "    # Decoder\n",
    "    lstm_ae.add(layers.GRU(16, activation='relu', return_sequences=True))\n",
    "    lstm_ae.add(layers.GRU(32, activation='relu', return_sequences=True))\n",
    "    lstm_ae.add(layers.GRU(64, activation='relu', return_sequences=True))\n",
    "    lstm_ae.add(layers.TimeDistributed(layers.Dense(78)))\n",
    "          \n",
    "   # compile\n",
    "    lstm_ae.compile(loss='mse', optimizer=optimizers.Adam(lr=lr), metrics=['accuracy'],)\n",
    "          \n",
    "    # fit\n",
    "    history = lstm_ae.fit(x_train_y0_scaled_reshape, x_train_y0_scaled_reshape,\n",
    "                              epochs=epochs, batch_size=batch,\n",
    "                              validation_data=(x_valid_y0_scaled_reshape, x_valid_y0_scaled_reshape))\n",
    "    # 모델 저장\n",
    "    lstm_ae.save('./model/gru_ae.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_ae = models.load_model('./newmodel/gru_ae.h5')\n",
    "\n",
    "# valid 데이터셋으로 예측 수행\n",
    "valid_x_predictions = gru_ae.predict(x_valid_scaled_reshape)\n",
    "\n",
    "# 복원 오차 산출\n",
    "mse = np.mean(np.power(x_valid_scaled - valid_x_predictions.reshape(valid_x_predictions.shape[0]*timesteps, 78), 2), axis=1)\n",
    "\n",
    "\n",
    "best_f1 = 0\n",
    "best_th = 0.04\n",
    "i = best_th\n",
    "# 최적의 threshold 산출\n",
    "while True:\n",
    "    if i == 0.1:\n",
    "        break\n",
    "    \n",
    "    print('현재: ',i, end='\\n')\n",
    "    mse_th = mse.copy()\n",
    "    mse_th[mse_th < i] = 0\n",
    "    mse_th[mse_th >= i] = 1\n",
    "    \n",
    "    f1 = f1_score(valid_label_rest, mse_th)*100\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        print('best f1 변경: ', best_f1, ' -> ', f1)\n",
    "        print('best_th 변경: ', best_th, ' -> ', i)\n",
    "        best_f1 = f1\n",
    "        best_th = i\n",
    "        \n",
    "        acc = accuracy_score(valid_label_rest, mse_th)*100\n",
    "        recall = recall_score(valid_label_rest, mse_th)*100\n",
    "        pre = precision_score(valid_label_rest, mse_th)*100\n",
    "        print(\"accuracy_score :\",acc)\n",
    "        print(\"recall_score :\",recall)\n",
    "        print(\"precision_score :\",pre)\n",
    "        print(\"f1_score :\",f1, end='\\n\\n')\n",
    "       \n",
    "    i -= 0.0002\n",
    "    del [[mse_th]]\n",
    "\n",
    "print('\\n\\n')        \n",
    "print('best f1 : ', best_f1)\n",
    "print('best th : ', best_th)\n",
    "\n",
    "# test 데이터 셋으로 예측 수행\n",
    "test_x_predictions = lstm_ae.predict(x_test_scaled_reshape)\n",
    "\n",
    "# 복원 오차 산출\n",
    "mse = np.mean(np.power(x_test_scaled - test_x_predictions.reshape(test_x_predictions.shape[0]*timesteps, 78), 2), axis=1)\n",
    "\n",
    "# threshold 기준으로 분류\n",
    "mse[mse < best_th] = 0\n",
    "mse[mse >= best_th] = 1\n",
    "\n",
    "# 결과 가시화\n",
    "print(\"accuracy_score :\",accuracy_score(test_label_rest, mse)*100)\n",
    "print(\"recall_score :\",recall_score(test_label_rest, mse)*100)\n",
    "print(\"precision_score :\",precision_score(test_label_rest, mse)*100)\n",
    "print(\"f1_score :\",f1_score(test_label_rest, mse)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
